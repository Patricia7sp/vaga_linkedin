name: Databricks CI/CD Pipeline

on:
  push:
    branches: [main, develop]
    paths:
      - 'app_production/agents/**'
      - 'app_production/agent_chat.py'
      - 'app_production/notebooks/**'
      - 'databricks_**'
      - '.github/workflows/databricks-deploy.yml'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy'
        required: true
        default: 'staging'
        type: choice
        options:
          - dev
          - staging
          - prod

env:
  PYTHON_VERSION: '3.10'

jobs:
  # ==================== DATABRICKS VALIDATION ====================
  databricks-validate:
    name: üîç Validate Databricks Code
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install databricks-cli databricks-sdk pytest
          pip install -r requirements.txt

      - name: Validate Python files
        run: |
          python -m py_compile app_production/agent_chat.py
          python -m py_compile app_production/notebooks/agent_chat_standalone.py
          find app_production/agents -name "*.py" -exec python -m py_compile {} \;

      - name: Run Databricks-specific tests
        run: |
          if [ -f tests/integration/test_databricks_*.py ]; then
            pytest tests/integration/test_databricks_*.py -v || echo "‚ö†Ô∏è No Databricks tests found or tests failed"
          else
            echo "‚ÑπÔ∏è No Databricks integration tests found - skipping"
          fi

  # ==================== DEPLOY TO DATABRICKS DEV ====================
  deploy-databricks-dev:
    name: üöÄ Deploy to Databricks DEV
    runs-on: ubuntu-latest
    needs: databricks-validate
    if: github.ref == 'refs/heads/develop'
    # environment:
    #   name: databricks-dev
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Databricks CLI
        run: |
          pip install databricks-cli databricks-sdk

      - name: Upload agent_chat.py to Databricks
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST_DEV }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN_DEV }}
        run: |
          python -c "
          from databricks.sdk import WorkspaceClient
          from databricks.sdk.service.workspace import ImportFormat
          import os
          
          w = WorkspaceClient(
              host=os.getenv('DATABRICKS_HOST'),
              token=os.getenv('DATABRICKS_TOKEN')
          )
          
          # Upload agent_chat.py
          with open('agent_chat.py', 'rb') as f:
              w.workspace.upload(
                  path='/Shared/dev/agent_chat.py',
                  content=f.read(),
                  format=ImportFormat.SOURCE,
                  overwrite=True
              )
          print('‚úÖ agent_chat.py uploaded to DEV')
          "

      - name: Upload notebooks
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST_DEV }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN_DEV }}
        run: |
          databricks workspace import_dir notebooks /Shared/dev/notebooks --overwrite

      - name: Update Databricks Job (DEV)
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST_DEV }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN_DEV }}
        run: |
          python -c "
          from databricks.sdk import WorkspaceClient
          import os
          
          w = WorkspaceClient(
              host=os.getenv('DATABRICKS_HOST'),
              token=os.getenv('DATABRICKS_TOKEN')
          )
          
          # Update job configuration
          # Job ID para DEV (criar se n√£o existir)
          print('‚úÖ Databricks job updated in DEV')
          "

  # ==================== DEPLOY TO DATABRICKS STAGING ====================
  deploy-databricks-staging:
    name: üé≠ Deploy to Databricks STAGING
    runs-on: ubuntu-latest
    needs: databricks-validate
    if: github.ref == 'refs/heads/main'
    # environment:
    #   name: databricks-staging
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Databricks CLI
        run: |
          # Install databricks CLI (provides 'databricks' command)
          pip install databricks-cli
          # Upgrade to latest version
          pip install --upgrade databricks-cli

      - name: Setup Databricks CLI
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          # Configure databricks CLI
          echo "[DEFAULT]" > ~/.databrickscfg
          echo "host = $DATABRICKS_HOST" >> ~/.databrickscfg
          echo "token = $DATABRICKS_TOKEN" >> ~/.databrickscfg
          
          echo "‚úÖ Databricks CLI configured"
      
      - name: Clean existing files
        run: |
          # Delete all variations to avoid naming conflicts
          for path in "/Shared/agent_chat" "/Shared/agent_chat.py" "/Shared/agent_chat_standalone" "/Shared/linkedin_pipeline_runner_notebook"; do
            databricks workspace delete "$path" --recursive 2>/dev/null && echo "üóëÔ∏è Deleted $path" || echo "‚ÑπÔ∏è  $path does not exist"
          done
      
      - name: Upload files to Databricks
        run: |
          # Upload agent_chat.py (source library)
          # Syntax: databricks workspace import SOURCE_PATH TARGET_PATH --language PYTHON --overwrite
          databricks workspace import \
            app_production/agent_chat.py \
            /Shared/agent_chat.py \
            --language PYTHON \
            --overwrite
          echo "‚úÖ agent_chat.py uploaded to STAGING"
          
          # Upload agent_chat_standalone (notebook for standalone job)
          databricks workspace import \
            app_production/notebooks/agent_chat_standalone.py \
            /Shared/agent_chat_standalone \
            --language PYTHON \
            --overwrite
          echo "‚úÖ agent_chat_standalone notebook uploaded to STAGING"
          
          # Upload linkedin_pipeline_runner_notebook (notebook for linkedin-pipeline-v4 job)
          databricks workspace import \
            app_production/notebooks/linkedin_pipeline_runner_notebook.py \
            /Shared/linkedin_pipeline_runner_notebook \
            --language PYTHON \
            --overwrite
          echo "‚úÖ linkedin_pipeline_runner_notebook uploaded to STAGING"
          
          # Upload DLT notebook - data_engineer (PRODU√á√ÉO)
          # Path NOVO para produ√ß√£o: /Shared/dlt_data_engineer_transformation
          databricks workspace import \
            app_production/agents/transform_agent/notebooks/dlt_data_engineer_transformation.py \
            /Shared/dlt_data_engineer_transformation \
            --language PYTHON \
            --overwrite
          echo "‚úÖ dlt_data_engineer_transformation uploaded to STAGING"
          
          # Upload DLT notebook - data_analytics (PRODU√á√ÉO)
          # Path NOVO para produ√ß√£o: /Shared/dlt_data_analytics_transformation
          databricks workspace import \
            app_production/agents/transform_agent/notebooks/dlt_data_analytics_transformation.py \
            /Shared/dlt_data_analytics_transformation \
            --language PYTHON \
            --overwrite
          echo "‚úÖ dlt_data_analytics_transformation uploaded to STAGING"
          
          # Upload DLT notebook - digital_analytics (PRODU√á√ÉO)
          # Path NOVO para produ√ß√£o: /Shared/dlt_digital_analytics_transformation
          databricks workspace import \
            app_production/agents/transform_agent/notebooks/dlt_digital_analytics_transformation.py \
            /Shared/dlt_digital_analytics_transformation \
            --language PYTHON \
            --overwrite
          echo "‚úÖ dlt_digital_analytics_transformation uploaded to STAGING"

  # ==================== DEPLOY TO DATABRICKS PRODUCTION ====================
  deploy-databricks-prod:
    name: üè≠ Deploy to Databricks PRODUCTION
    runs-on: ubuntu-latest
    needs: deploy-databricks-staging
    if: github.ref == 'refs/heads/main' && github.event.inputs.environment == 'prod'
    # environment:
    #   name: databricks-production
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Databricks CLI
        run: |
          pip install databricks-cli databricks-sdk

      - name: Upload agent_chat.py to Databricks PROD
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          python -c "
          from databricks.sdk import WorkspaceClient
          from databricks.sdk.service.workspace import ImportFormat
          import os
          
          w = WorkspaceClient(
              host=os.getenv('DATABRICKS_HOST'),
              token=os.getenv('DATABRICKS_TOKEN')
          )
          
          # Upload agent_chat.py to PRODUCTION
          with open('agent_chat.py', 'rb') as f:
              w.workspace.upload(
                  path='/Shared/agent_chat.py',
                  content=f.read(),
                  format=ImportFormat.SOURCE,
                  overwrite=True
              )
          print('‚úÖ agent_chat.py uploaded to PRODUCTION')
          "

      - name: Run validation tests on PROD
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          # Execute validation job
          echo "Running validation tests..."
