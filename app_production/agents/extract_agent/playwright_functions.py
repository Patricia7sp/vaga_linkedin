#!/usr/bin/env python3
"""
FunÃ§Ãµes de extraÃ§Ã£o LinkedIn usando Playwright (substitui Selenium)
Performance: 3-5x mais rÃ¡pido, cÃ³digo 70% mais simples
"""

import random
from datetime import datetime
from typing import Dict, List
from urllib.parse import quote

from playwright.sync_api import TimeoutError as PlaywrightTimeout
from playwright.sync_api import sync_playwright


def extract_jobs_via_linkedin_playwright(
    search_term: str, max_results: int = 10, category: str = "general"
) -> List[Dict]:
    """
    Extrai vagas do LinkedIn usando Playwright (OTIMIZADO e RÃPIDO)

    Args:
        search_term: Termo de busca
        max_results: MÃ¡ximo de resultados (default: 10)
        category: Categoria da vaga

    Returns:
        Lista de vagas extraÃ­das
    """
    jobs = []

    print(f"ðŸŽ­ Extraindo vagas do LinkedIn para '{search_term}' (Playwright)...")

    with sync_playwright() as p:
        try:
            # Launch browser (headless, otimizado)
            browser = p.chromium.launch(
                headless=True,
                args=[
                    "--no-sandbox",
                    "--disable-setuid-sandbox",
                    "--disable-dev-shm-usage",
                    "--disable-gpu",
                    "--no-first-run",
                    "--no-zygote",
                    "--single-process",
                    "--disable-extensions",
                ],
            )

            # Create context with realistic settings
            context = browser.new_context(
                viewport={"width": 1920, "height": 1080},
                user_agent="Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            )

            page = context.new_page()

            # Try to load cookies from GCS/local
            cookies_loaded = _load_linkedin_cookies(context)
            if cookies_loaded:
                print("ðŸª Cookies carregados")

            # Build LinkedIn search URL
            encoded_search = quote(search_term)
            linkedin_url = f"https://www.linkedin.com/jobs/search/?keywords={encoded_search}&location=Worldwide&f_TPR=r1728000&f_LF=f_AL&sortBy=DD"

            print(f"ðŸŒ Acessando: {linkedin_url}")

            # Navigate with timeout
            try:
                page.goto(linkedin_url, wait_until="domcontentloaded", timeout=30000)
                page.wait_for_timeout(3000)  # Brief wait for dynamic content
            except PlaywrightTimeout:
                print("âš ï¸ Timeout ao carregar pÃ¡gina")
                browser.close()
                return jobs

            # Find job cards (Playwright auto-waits)
            job_card_selectors = [
                ".job-search-card",
                ".base-search-card",
                ".base-card",
                ".jobs-search-results__list-item",
            ]

            job_cards = None
            for selector in job_card_selectors:
                try:
                    job_cards = page.query_selector_all(selector)
                    if job_cards and len(job_cards) > 3:
                        print(f"âœ… Encontrados {len(job_cards)} elementos com: {selector}")
                        break
                except Exception:
                    continue

            if not job_cards or len(job_cards) == 0:
                print("âš ï¸ Nenhuma vaga encontrada")
                browser.close()
                return jobs

            print(f"ðŸ“¡ LinkedIn encontrou {len(job_cards)} vagas para '{search_term}'")

            # Extract data from cards (FAST - no individual navigation)
            for idx, card in enumerate(job_cards[:max_results], 1):
                try:
                    # Minimal delay (Playwright is faster than Selenium)
                    if idx > 1:
                        page.wait_for_timeout(random.randint(200, 500))

                    # Extract title (simplified with Playwright)
                    job_title = None
                    title_selectors = ["h3.base-search-card__title", ".job-search-card__title", "h3 a", "h3"]

                    for sel in title_selectors:
                        try:
                            title_elem = card.query_selector(sel)
                            if title_elem:
                                job_title = title_elem.inner_text().strip()
                                if job_title and len(job_title) > 3:
                                    break
                        except Exception:
                            continue

                    if not job_title:
                        continue

                    # Basic relevance filter
                    if not _is_relevant(job_title, search_term, category):
                        continue

                    # Extract company
                    company = "N/A"
                    company_selectors = ["h4.base-search-card__subtitle", ".job-search-card__subtitle-link", "h4"]

                    for sel in company_selectors:
                        try:
                            comp_elem = card.query_selector(sel)
                            if comp_elem:
                                company = comp_elem.inner_text().strip()
                                if company:
                                    break
                        except Exception:
                            continue

                    # Extract location
                    location = "Global"
                    try:
                        loc_elem = card.query_selector(".job-search-card__location")
                        if loc_elem:
                            location = loc_elem.inner_text().strip()
                    except Exception:
                        pass

                    # Extract job URL
                    job_url = f"https://linkedin.com/jobs/search/{idx}"
                    try:
                        link_elem = card.query_selector('h3 a, a[href*="/jobs/view/"]')
                        if link_elem:
                            href = link_elem.get_attribute("href")
                            if href:
                                job_url = href if href.startswith("http") else f"https://linkedin.com{href}"
                    except Exception:
                        pass

                    # Work modality detection (simplified)
                    work_modality = "N/A"
                    text_content = (job_title + " " + company + " " + location).lower()
                    if "remot" in text_content or "home office" in text_content:
                        work_modality = "Remoto"
                    elif "hÃ­brid" in text_content or "hybrid" in text_content:
                        work_modality = "HÃ­brido"
                    elif "presencial" in text_content or "on-site" in text_content:
                        work_modality = "Presencial"

                    # Create job object
                    job = {
                        "title": job_title,
                        "company": company,
                        "location": location,
                        "job_url": job_url,
                        "description": "N/A",  # No individual page navigation for speed
                        "work_modality": work_modality,
                        "seniority": "N/A",
                        "job_type": "N/A",
                        "scraped_at": datetime.now().isoformat(),
                        "category": category or "general",
                        "search_term": search_term,
                    }

                    jobs.append(job)
                    print(f"âœ… Vaga aceita: {job_title} ({company})")

                except Exception as e:
                    print(f"âš ï¸ Erro ao processar vaga {idx}: {e}")
                    continue

            browser.close()
            print(f"âœ… {len(jobs)} vagas vÃ¡lidas extraÃ­das via LinkedIn autenticado")

        except Exception as e:
            print(f"âŒ Erro geral no Playwright: {e}")
            return jobs

    return jobs


def _load_linkedin_cookies(context) -> bool:
    """Tenta carregar cookies salvos do LinkedIn"""
    try:
        # Try to load from GCS or local file
        cookie_manager = LinkedInCookieManager()
        cookies_data = cookie_manager._download_from_gcs()

        if cookies_data:
            context.add_cookies(cookies_data)
            return True
    except Exception:
        pass

    return False


def _is_relevant(title: str, search_term: str, category: str) -> bool:
    """Filtro simples de relevÃ¢ncia"""
    title_lower = title.lower()
    search_lower = search_term.lower()

    # Basic keyword matching
    keywords = search_lower.split()
    matches = sum(1 for kw in keywords if kw in title_lower)

    return matches >= max(1, len(keywords) // 2)


# Import LinkedInCookieManager if available
try:
    from .extract_agent import LinkedInCookieManager
except ImportError:
    try:
        from extract_agent import LinkedInCookieManager
    except ImportError:
        # Fallback: simple mock
        class LinkedInCookieManager:
            def _download_from_gcs(self):
                return None
