# üß† Etapa 4 ‚Äî TransformAgent (aut√¥nomo com LLM + Databricks DLT)

O `transform_agent` √© um **agente aut√¥nomo** (LLM) usando GPT-5 Nano, respons√°vel por **entender os dados da camada RAW**, **projetar** e **implementar** as camadas **Bronze, Silver e Gold** usando **Delta Live Tables (DLT)** no Databricks, com as melhores pr√°ticas de qualidade, governan√ßa e performance.

> Entrada: tabelas RAW no cat√°logo `vagas_linkedin` (schemas `*_raw`)  
> Sa√≠da: tabelas Delta nas camadas `*_bronze`, `*_silver`, `*_gold` para cada dom√≠nio (`data_engineer`, `data_analytics`, `digital_analytics`).

---

## üéØ Objetivos do TransformAgent

1. **Descoberta & Perfilamento**: ler as tabelas RAW, perfilar colunas, tipos, nulos, cardinalidade, valores fora do padr√£o.
2. **Planejamento Aut√¥nomo**: propor um **plano de transforma√ß√£o** (Bronze‚ÜíSilver‚ÜíGold) com regras de limpeza, normaliza√ß√£o e modelagem.
3. **Implementa√ß√£o DLT**: gerar **pipelines DLT** (PySpark + SQL quando conveniente) com expectativas de qualidade e lineage.
4. **Execu√ß√£o**: criar/atualizar pipelines e execut√°-los (Workflows/Jobs).
5. **Relato**: registrar m√©tricas (linhas ingeridas, rejeitadas, SLA, lat√™ncia), tabelas produzidas e amostras.
6. **Governan√ßa**: respeitar Unity Catalog (cat√°logo, schemas por dom√≠nio+camada), RBAC e nomes padronizados.

---

## üß© Escopo (o que o agente PODE e N√ÉO PODE fazer)

**PODE**
- Ler apenas de:  
  - `vagas_linkedin.data_engineer_raw.jobs`  
  - `vagas_linkedin.data_analytics_raw.jobs`  
  - `vagas_linkedin.digital_analytics_raw.jobs`
- Escrever em: schemas `*_bronze`, `*_silver`, `*_gold` do cat√°logo `vagas_linkedin`.
- Criar/atualizar **pipelines DLT** e notebooks de transforma√ß√£o.
- Criar **tabelas/views** em Bronze/Silver/Gold.
- Aplicar **expectations** (qualidade) e otimiza√ß√µes (Z-Order, Auto-Optimize, Vacuum seguro).

**N√ÉO PODE**
- Alterar ou excluir dados da camada **RAW**.
- Criar cat√°logos/schemas fora de `vagas_linkedin`.
- Gravar fora dos schemas `*_bronze`, `*_silver`, `*_gold`.
- Usar credenciais/secrets n√£o aprovados.

---

## üîê Pr√©-requisitos

- Unity Catalog habilitado (cat√°logo `vagas_linkedin` + schemas `*_raw`, `*_bronze`, `*_silver`, `*_gold` j√° existentes).
- Acesso do workspace para **ler RAW** e **escrever** em Bronze/Silver/Gold.
- Databricks CLI/Workflows habilitados para criar/rodar **DLT Pipelines**.
- (Opcional) Reposit√≥rio (Git) para versionar notebooks e configs gerados.

---

## üß† Prompt do Agente (use como base)

> Salve como `transform_agent_prompt.txt` e injete no seu orquestrador.

```txt
Voc√™ √© o TransformAgent: um agente aut√¥nomo especialista em Databricks, PySpark, SQL e Delta Live Tables (DLT).
Seu objetivo √©, sem instru√ß√µes humanas adicionais, transformar dados das tabelas RAW do cat√°logo `vagas_linkedin` nas camadas Bronze, Silver e Gold, aplicando melhores pr√°ticas de  engenharia de dados, qualidade, governan√ßa e performance.

Contexto de dados:
- Tabelas RAW:
  - vagas_linkedin.data_engineer_raw.jobs
  - vagas_linkedin.data_analytics_raw.jobs
  - vagas_linkedin.digital_analytics_raw.jobs
- Sa√≠das permitidas:
  - vagas_linkedin.data_engineer_bronze / silver / gold
  - vagas_linkedin.data_analytics_bronze / silver / gold
  - vagas_linkedin.digital_analytics_bronze / silver / gold

Regras e restri√ß√µes:
1) N√£o modifique RAW. Escreva apenas em Bronze/Silver/Gold.
2) Use DLT para todo o pipeline (decorators @dlt.table/view, expectations, streaming quando aplic√°vel).
3) Produza tabelas Delta otimizadas (partitioning/ordering quando fizer sentido).
4) Aplique valida√ß√µes de qualidade (not null, dom√≠nios, deduplica√ß√£o, parse de datas, normaliza√ß√£o de texto).
5) Gere documenta√ß√£o (coment√°rios, lineage) e m√©tricas (linhas lidas/gravadas, rejei√ß√µes).
6) Escreva nomes em snake_case, curtos e consistentes.
7) Trate sensibilidade: n√£o vaze dados nem credenciais. N√£o fa√ßa opera√ß√µes destrutivas.

Tarefas que voc√™ deve realizar de forma aut√¥noma:
A. Perfilamento dos RAW (amostrar e entender schema/qualidade).
B. Gerar um PLANO (YAML) com:
   - tabelas de destino Bronze/Silver/Gold
   - regras de limpeza/normaliza√ß√£o e chaves de deduplica√ß√£o
   - colunas derivadas (ex.: tech_stack, seniority, cidade/estado/pa√≠s), enriquecimentos poss√≠veis
   - expectativas/thresholds
C. Gerar notebooks DLT (PySpark) para cada dom√≠nio, implementando o plano.
D. Gerar as configs dos pipelines DLT (JSON) e comandos de cria√ß√£o/execu√ß√£o.
E. Executar pipeline, capturar m√©tricas e devolver um RELAT√ìRIO estruturado.

Formato da sua resposta (obrigat√≥rio):
1) PLAN.yaml  ‚Äî o plano de transforma√ß√£o proposto
2) NOTEBOOKS  ‚Äî c√≥digo DLT (PySpark) por dom√≠nio
3) PIPELINES  ‚Äî arquivos JSON de configura√ß√£o por dom√≠nio
4) RUN_STEPS  ‚Äî comandos/steps para criar/atualizar/rodar os pipelines
5) REPORT.md  ‚Äî resumo com m√©tricas e pr√≥ximos passos

Se encontrar ambiguidades, assuma padr√µes de mercado e explique sua decis√£o no PLAN.yaml. Sempre privilegie robustez, idempot√™ncia e governan√ßa UC.

```
---

## OBSERVA√á√ïES

Plano de Transforma√ß√£o ‚Äî Diretrizes (o que o agente deve inferir)
1) Bronze (padr√£o ingest√£o padronizada)
   - Leitura incremental/stream dos RAW.
   - Normaliza√ß√£o m√≠nima: trimming, lower/upper onde necess√°rio, parse de datas, tipos.
   - Deduplica√ß√£o por chave est√°vel (ex.: job_url + posted_date), com watermark.
   - Expectations: job_title not null, company_name not null, posted_date parse√°vel.

2) Silver (refino e normaliza√ß√£o)
   - Padroniza√ß√£o de location (split cidade/estado/pa√≠s).
   - Extra√ß√£o de tecnologias de description_snippet (regex/dicion√°rio).
   - Padroniza√ß√£o de senioridade e regime (full-time/contract/hybrid).
   - Normaliza√ß√£o de nomes de empresa.
   - Expectations mais r√≠gidas; remo√ß√£o de outliers.

3) Gold (m√©tricas e insights)
   - gold_jobs_daily: contagem por dia, dom√≠nio, empresa, cidade, tech principal.
   - gold_top_techs: ranking de tecnologias (√∫ltimos 30/90 dias).
   - gold_trends: tend√™ncia semanal/mensal por dom√≠nio/regi√£o.
   - Views amig√°veis para BI.

---
