# ðŸŽ¯ ConfiguraÃ§Ã£o dos 3 Jobs DLT Separados

## âš ï¸ IMPORTANTE: Daily Limit Exhausted

Sua conta Databricks Free Edition estÃ¡ com erro:
```
Organization 4343877046393065 has been cancelled or is not active yet.
```

Isso acontece quando atinge o **daily limit** (limite diÃ¡rio de uso).

**SOLUÃ‡Ã•ES:**
1. âœ… Aguardar 24h para resetar o limite diÃ¡rio
2. âœ… Criar jobs manualmente via UI do Databricks
3. âœ… Executar pipelines manualmente (via UI)

---

## ðŸ“‹ JOB 1: Data Engineer Pipeline

**Nome:** `dlt-data-engineer-pipeline`

**Schedule:** 
- Dias: Segunda a Sexta
- HorÃ¡rios: 08:30, 12:30, 21:30 (HorÃ¡rio de BrasÃ­lia)
- Cron: `0 30 8,12,21 ? * MON-FRI`

**Task:**
- **Task Key:** `run-pipeline`
- **Type:** Notebook
- **Notebook Path:** `/Shared/linkedin_pipeline_runner_notebook`
- **Parameters:**
  - `pipeline`: `data_engineer`
  - `environment`: `production`
- **Timeout:** 3600 segundos (1 hora)
- **Max Retries:** 1

---

## ðŸ“‹ JOB 2: Data Analytics Pipeline

**Nome:** `dlt-data-analytics-pipeline`

**Schedule:** 
- Dias: Segunda a Sexta
- HorÃ¡rios: 09:00, 13:00, 22:00 (HorÃ¡rio de BrasÃ­lia)
- Cron: `0 0 9,13,22 ? * MON-FRI`

**Task:**
- **Task Key:** `run-pipeline`
- **Type:** Notebook
- **Notebook Path:** `/Shared/linkedin_pipeline_runner_notebook`
- **Parameters:**
  - `pipeline`: `data_analytics`
  - `environment`: `production`
- **Timeout:** 3600 segundos (1 hora)
- **Max Retries:** 1

---

## ðŸ“‹ JOB 3: Digital Analytics Pipeline

**Nome:** `dlt-digital-analytics-pipeline`

**Schedule:** 
- Dias: Segunda a Sexta
- HorÃ¡rios: 10:00, 14:00, 23:00 (HorÃ¡rio de BrasÃ­lia)
- Cron: `0 0 10,14,23 ? * MON-FRI`

**Task:**
- **Task Key:** `run-pipeline`
- **Type:** Notebook
- **Notebook Path:** `/Shared/linkedin_pipeline_runner_notebook`
- **Parameters:**
  - `pipeline`: `digital_analytics`
  - `environment`: `production`
- **Timeout:** 3600 segundos (1 hora)
- **Max Retries:** 1

---

## ðŸŽ¯ VANTAGENS DESTA CONFIGURAÃ‡ÃƒO:

### âœ… Respeita Free Edition
- **1 pipeline por vez** (limitaÃ§Ã£o documentada)
- **HorÃ¡rios espaÃ§ados** (30 min entre jobs)
- **Evita concorrÃªncia** entre pipelines

### âœ… DistribuiÃ§Ã£o de Carga
```
08:30 â†’ data_engineer
09:00 â†’ data_analytics (30 min depois)
10:00 â†’ digital_analytics (1h depois)

12:30 â†’ data_engineer
13:00 â†’ data_analytics
14:00 â†’ digital_analytics

21:30 â†’ data_engineer
22:00 â†’ data_analytics
23:00 â†’ digital_analytics
```

### âœ… Evita Daily Limit
- Jobs executam em horÃ¡rios diferentes
- Permite "respirar" entre execuÃ§Ãµes
- Reduz chance de atingir limite diÃ¡rio

---

## ðŸ“ COMO CRIAR JOBS (MANUALMENTE VIA UI):

### **Passo 1: Acessar Workflows**
1. Databricks UI â†’ Menu lateral
2. Click em **"Workflows"**
3. Click em **"Create Job"**

### **Passo 2: Configurar Job**
1. **Name:** (copiar nome acima)
2. **Task:**
   - Click "Add task"
   - **Type:** Notebook
   - **Notebook path:** `/Shared/linkedin_pipeline_runner_notebook`
   - **Parameters:** Adicionar 2 parÃ¢metros:
     - `pipeline`: (valor conforme job)
     - `environment`: `production`
   - **Timeout:** 3600
   - **Retries:** 1
3. **Schedule:**
   - Click "Add trigger" â†’ "Scheduled"
   - **Cron:** (copiar cron acima)
   - **Timezone:** America/Sao_Paulo
   - **Pause status:** UNPAUSED

### **Passo 3: Salvar**
- Click "Create"
- Job estarÃ¡ pronto!

**Repetir para os 3 jobs.**

---

## ðŸš€ TESTE MANUAL (ANTES DE AGENDAR):

Antes de ativar schedule, teste manualmente:

1. VÃ¡ em **Workflows** â†’ Selecione job
2. Click **"Run now"**
3. Aguarde execuÃ§Ã£o (deve levar 9-11 minutos)
4. Verifique logs e sucesso

**IMPORTANTE:** Teste **UM job por vez** para nÃ£o atingir daily limit!

---

## âš ï¸ SOBRE O DAILY LIMIT EXHAUSTED:

### **O que Ã©:**
- Databricks Free Edition tem **limite diÃ¡rio nÃ£o divulgado** de:
  - Compute hours (horas de processamento)
  - Data processed (dados processados)
  - Pipeline updates (execuÃ§Ãµes de pipeline)

### **Como evitar:**
1. âœ… **Executar menos jobs** por dia
2. âœ… **EspaÃ§ar horÃ¡rios** (30min+ entre jobs)
3. âœ… **Evitar full_refresh** (usar incremental)
4. âœ… **NÃ£o rodar mÃºltiplos pipelines** simultaneamente

### **Quando acontece:**
- Geralmente apÃ³s 10-15 execuÃ§Ãµes de pipeline por dia
- Ou apÃ³s processar muito volume de dados
- Reseta a cada 24 horas (meia-noite UTC)

### **SoluÃ§Ã£o definitiva:**
- **Upgrade para Databricks pago** ($$$)
- Permite pipelines ilimitados
- Sem daily limits

---

## ðŸ”„ ALTERNATIVA: Executar 1 pipeline por dia

Se daily limit continuar problema, **reduzir para 1 execuÃ§Ã£o por dia**:

```
Segunda: data_engineer Ã s 08:30
TerÃ§a: data_analytics Ã s 08:30
Quarta: digital_analytics Ã s 08:30
Quinta: data_engineer Ã s 08:30
Sexta: data_analytics Ã s 08:30
SÃ¡bado: digital_analytics Ã s 08:30
```

**Cron para rotaÃ§Ã£o:**
- Segunda/Quinta: `0 30 8 ? * MON,THU`
- TerÃ§a/Sexta: `0 30 8 ? * TUE,FRI`
- Quarta/SÃ¡bado: `0 30 8 ? * WED,SAT`

---

## ðŸ“Š MONITORAMENTO:

ApÃ³s criar jobs, monitore:

1. âœ… **Duration** de cada execuÃ§Ã£o (deveria ser 9-11 min)
2. âœ… **Success rate** (deveria ser >90%)
3. âœ… **Logs** para mensagens de erro
4. âœ… **Tabelas Gold** para validar dados processados

Se continuar em 1 minuto â†’ Daily limit ativo!

---

**âœ… Jobs configurados com sucesso!**
**âœ… Estrutura compatÃ­vel com Free Edition!**
**âœ… Evita concorrÃªncia entre pipelines!**
