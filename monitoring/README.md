# üîç Monitoramento - Vagas LinkedIn

Monitoramento completo do pipeline: GCP (Cloud Run) + Databricks Jobs.

---

## üìä **Vis√£o Geral**

Este sistema monitora automaticamente:

### **‚òÅÔ∏è Google Cloud Platform:**
- ‚úÖ Cloud Run Jobs (staging/production)
- ‚úÖ Execu√ß√µes e status
- ‚úÖ Logs e erros
- ‚úÖ Dados no Cloud Storage (freshness)

### **üß± Databricks:**
- ‚úÖ Jobs DLT (Transform Agent)
- ‚úÖ Agent Chat (Telegram notifications)
- ‚úÖ Taxa de sucesso dos runs
- ‚úÖ Alertas de falhas

---

## üöÄ **Como Funciona**

### **1. Monitoramento Autom√°tico via GitHub Actions**

**Workflow:** `.github/workflows/monitoring.yml`

**Schedule:** A cada **6 horas**

**O que faz:**
1. Roda smoke tests no Cloud Run
2. Verifica status dos jobs Databricks
3. Envia alertas via Telegram se houver problemas
4. Gera relat√≥rio de monitoramento

**Executar manualmente:**
```bash
# Via GitHub Actions UI
# Ou via gh CLI:
gh workflow run monitoring.yml
```

---

### **2. Terraform - Alertas GCP**

**Arquivo:** `terraform/monitoring.tf`

**Recursos criados:**
- üìß **Notification Channel** (email)
- üö® **Alert Policies** (3 alertas)
- üìä **Dashboard** (m√©tricas Cloud Run)
- ‚è∞ **Cloud Scheduler** (execu√ß√£o autom√°tica 3x/dia)

**Alertas configurados:**

| Alerta | Condi√ß√£o | A√ß√£o |
|--------|----------|------|
| **Job Failures** | Run falhou | Email imediato |
| **Slow Execution** | > 10 minutos | Email |
| **No Executions** | Sem runs em 24h | Email |

**Aplicar:**
```bash
cd terraform/
terraform init
terraform apply -var manage_gcp_resources=true
```

---

### **3. Script Python - Monitor Databricks**

**Arquivo:** `monitoring/databricks_monitor.py`

**O que faz:**
- Lista todos os jobs cr√≠ticos
- Verifica √∫ltima execu√ß√£o
- Calcula taxa de sucesso (√∫ltimos 5 runs)
- Envia alertas Telegram se houver falhas

**Jobs monitorados:**
- `linkedin-agent-chat-notifications`
- `linkedin-dlt-pipeline`
- `linkedin-extract-agent`

**Executar manualmente:**
```bash
# Configurar vari√°veis
export DATABRICKS_HOST="https://dbc-xxxxx.cloud.databricks.com"
export DATABRICKS_TOKEN="dapi..."
export TELEGRAM_BOT_TOKEN="123456:ABC..."
export TELEGRAM_CHAT_ID="123456789"

# Executar
python monitoring/databricks_monitor.py
```

**Sa√≠da esperada:**
```
üîç Monitorando jobs cr√≠ticos do Databricks...
============================================================
‚úÖ linkedin-agent-chat-notifications
   Status: HEALTHY
   Mensagem: √öltimo run bem-sucedido h√° 2.3h
   Taxa de Sucesso: 100.0%

‚ö†Ô∏è linkedin-dlt-pipeline
   Status: STALE
   Mensagem: √öltimo run bem-sucedido h√° 26.5h
   Taxa de Sucesso: 80.0%

============================================================
‚úÖ Monitoramento conclu√≠do
üìä Jobs verificados: 3
üì® Alertas enviados: 1
```

---

## üéØ **Cloud Scheduler - Migra√ß√£o do V5 para Staging**

### **Antes (manual):**
Voc√™ tinha um Cloud Scheduler apontando para `vaga-linkedin-prod-v5`.

### **Agora (Terraform):**
O Terraform cria automaticamente um novo scheduler para `vaga-linkedin-prod-staging`.

**Configura√ß√£o:**
```hcl
# terraform/monitoring.tf
resource "google_cloud_scheduler_job" "cloud_run_job_trigger" {
  name        = "vaga-linkedin-prod-staging-trigger"
  description = "Trigger autom√°tico 3x/dia"
  
  # 08:00, 14:00, 20:00 BRT
  schedule    = "0 8,14,20 * * *"
  time_zone   = "America/Sao_Paulo"
  
  http_target {
    uri = "https://us-central1-run.googleapis.com/.../jobs/vaga-linkedin-prod-staging:run"
    ...
  }
}
```

**Aplicar:**
```bash
cd terraform/
terraform apply -var manage_gcp_resources=true
```

**Verificar:**
```bash
gcloud scheduler jobs list --location=us-central1 --project=vaga-linkedin
```

**Deletar scheduler antigo (se quiser):**
```bash
# Listar schedulers existentes
gcloud scheduler jobs list --location=us-central1 --project=vaga-linkedin

# Deletar o antigo (se existir)
gcloud scheduler jobs delete vaga-linkedin-prod-v5-trigger \
  --location=us-central1 \
  --project=vaga-linkedin
```

---

## üìß **Configura√ß√£o de Notifica√ß√µes**

### **Email (GCP Monitoring):**

Configurado via Terraform:
```hcl
variable "current_user_email" {
  description = "Email para receber alertas"
  type        = string
}
```

**Aplicar:**
```bash
cd terraform/
terraform apply -var current_user_email="seu-email@gmail.com"
```

### **Telegram (Databricks):**

1. **Criar bot via BotFather**
2. **Obter Chat ID**
3. **Configurar no Databricks Secrets:**

```bash
databricks secrets create-scope vagas_linkedin
databricks secrets put --scope vagas_linkedin --key telegram-bot-token
databricks secrets put --scope vagas_linkedin --key telegram-chat-id
```

4. **Configurar no GitHub Secrets:**

```bash
gh secret set TELEGRAM_BOT_TOKEN
gh secret set TELEGRAM_CHAT_ID
```

---

## üìä **Dashboard GCP**

**Criado via Terraform:**
- Execu√ß√µes por status (sucesso/falha)
- Tempo de execu√ß√£o
- Logs recentes

**Acessar:**
```bash
# Via CLI
gcloud monitoring dashboards list --project=vaga-linkedin

# Via Console
https://console.cloud.google.com/monitoring/dashboards?project=vaga-linkedin
```

---

## üß™ **Smoke Tests**

**Arquivo:** `tests/smoke/test_cloud_run_smoke.py`

**O que testa:**
- ‚úÖ Job existe no Cloud Run
- ‚úÖ Imagem est√° correta
- ‚úÖ Recursos (CPU/RAM) configurados
- ‚úÖ Secret RAPIDAPI_KEY presente
- ‚úÖ Execu√ß√µes recentes
- ‚úÖ Dados no Cloud Storage
- ‚úÖ Logs sendo gerados

**Executar localmente:**
```bash
# Instalar depend√™ncias
pip install pytest google-cloud-run google-cloud-logging google-cloud-storage

# Configurar vari√°veis
export GOOGLE_APPLICATION_CREDENTIALS="/path/to/gcp-credentials.json"
export GCP_PROJECT_ID="vaga-linkedin"
export GCP_REGION="us-central1"
export ENVIRONMENT="staging"

# Rodar testes
pytest tests/smoke/ -v
```

**No CI/CD:**
Roda automaticamente ap√≥s cada deploy (`.github/workflows/ci-cd-pipeline.yml`).

---

## üîß **Troubleshooting**

### **Problema: Alertas n√£o est√£o sendo enviados**

**Verificar:**
1. Notification channel configurado?
```bash
gcloud alpha monitoring channels list --project=vaga-linkedin
```

2. Email confirmado?
- Check inbox/spam
- Google Cloud Console ‚Üí Monitoring ‚Üí Notification Channels

3. Alert policies habilitadas?
```bash
gcloud alpha monitoring policies list --project=vaga-linkedin
```

### **Problema: Databricks monitor falha**

**Verificar:**
1. Token v√°lido?
```bash
curl -H "Authorization: Bearer $DATABRICKS_TOKEN" \
  "$DATABRICKS_HOST/api/2.0/clusters/list"
```

2. Jobs existem?
```bash
python monitoring/databricks_monitor.py
```

3. Telegram configurado?
```bash
curl "https://api.telegram.org/bot$TELEGRAM_BOT_TOKEN/getMe"
```

### **Problema: Cloud Scheduler n√£o est√° rodando**

**Verificar:**
1. Scheduler criado?
```bash
gcloud scheduler jobs list --location=us-central1 --project=vaga-linkedin
```

2. Service account tem permiss√µes?
```bash
gcloud projects get-iam-policy vaga-linkedin \
  --flatten="bindings[].members" \
  --filter="bindings.members:linkedin-scraper@vaga-linkedin.iam.gserviceaccount.com"
```

3. For√ßar execu√ß√£o manual:
```bash
gcloud scheduler jobs run vaga-linkedin-prod-staging-trigger \
  --location=us-central1 \
  --project=vaga-linkedin
```

---

## üìö **Refer√™ncias**

- [Cloud Monitoring Docs](https://cloud.google.com/monitoring/docs)
- [Cloud Scheduler Docs](https://cloud.google.com/scheduler/docs)
- [Databricks Jobs API](https://docs.databricks.com/api/workspace/jobs)
- [Telegram Bot API](https://core.telegram.org/bots/api)

---

## ‚úÖ **Checklist de Implementa√ß√£o**

- [ ] ‚úÖ Smoke tests criados
- [ ] ‚úÖ Monitoring Terraform aplicado
- [ ] ‚úÖ Cloud Scheduler configurado (3x/dia)
- [ ] ‚úÖ Email alerts configurados
- [ ] ‚úÖ Telegram bot configurado
- [ ] ‚úÖ Databricks monitor testado
- [ ] ‚úÖ GitHub Actions workflow ativo
- [ ] ‚úÖ Dashboard GCP acess√≠vel
- [ ] ‚úÖ Scheduler antigo (v5) deletado

---

**√öltima atualiza√ß√£o:** 08/10/2025  
**Vers√£o:** 1.0  
**Status:** ‚úÖ Pronto para uso
